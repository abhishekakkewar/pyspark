{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "002db1b7",
   "metadata": {},
   "source": [
    "In this Tutorial we will cover  \n",
    "\n",
    "* pyspark dataframe  \n",
    "* reading the dataset   \n",
    "* checking the datatypes of the columns  \n",
    "* selecting columns and indexing  \n",
    "* check describe option similar to Pandas   \n",
    "* adding columns   \n",
    "* Dropping columns   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d954092",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "230dc84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fb10f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Dataframe').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbf933cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://Abhi-PC:4045\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Dataframe</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x19c8b1338e0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "843418fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read the dataset\n",
    "df_spark =  spark.read.option('header','true').csv('Book1.csv', inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "599e00ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+\n",
      "|  Name|Age|Experience|\n",
      "+------+---+----------+\n",
      "|  Abhi| 26|        10|\n",
      "|  Neha| 27|         8|\n",
      "|Milind| 27|         4|\n",
      "+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fc7bc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Check the schema\n",
    "df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f12289b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = spark.read.csv('Book1.csv', header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27f34d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+\n",
      "|  Name|Age|Experience|\n",
      "+------+---+----------+\n",
      "|  Abhi| 26|        10|\n",
      "|  Neha| 27|         8|\n",
      "|Milind| 27|         4|\n",
      "+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d30c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data frame is one type of data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa44fc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "203e2367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Age', 'Experience']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1af24055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Name='Abhi', Age=26, Experience=10),\n",
       " Row(Name='Neha', Age=27, Experience=8)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4913218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+\n",
      "|  Name|Age|Experience|\n",
      "+------+---+----------+\n",
      "|  Abhi| 26|        10|\n",
      "|  Neha| 27|         8|\n",
      "|Milind| 27|         4|\n",
      "+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3fc2c541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|  Name|\n",
      "+------+\n",
      "|  Abhi|\n",
      "|  Neha|\n",
      "|Milind|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#selecting \"Name\" column\n",
    "Name_col = df_spark.select('Name')\n",
    "Name_col.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59776e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n",
      "|  Name|Experience|\n",
      "+------+----------+\n",
      "|  Abhi|        10|\n",
      "|  Neha|         8|\n",
      "|Milind|         4|\n",
      "+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NameExe_col = df_spark.select(['Name','Experience'])\n",
    "NameExe_col.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "842d026b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Name', 'string'), ('Age', 'int'), ('Experience', 'int')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d572b0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------------------+-----------------+\n",
      "|summary|Name|               Age|       Experience|\n",
      "+-------+----+------------------+-----------------+\n",
      "|  count|   3|                 3|                3|\n",
      "|   mean|null|26.666666666666668|7.333333333333333|\n",
      "| stddev|null|0.5773502691896258|3.055050463303893|\n",
      "|    min|Abhi|                26|                4|\n",
      "|    max|Neha|                27|               10|\n",
      "+-------+----+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb626149",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Adding columns in pyspark data frame\n",
    "df_spark = df_spark.withColumn('Experience After 2 yrs',df_spark[\"Experience\"]+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "167007bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+----------------------+\n",
      "|  Name|Age|Experience|Experience After 2 yrs|\n",
      "+------+---+----------+----------------------+\n",
      "|  Abhi| 26|        10|                    12|\n",
      "|  Neha| 27|         8|                    10|\n",
      "|Milind| 27|         4|                     6|\n",
      "+------+---+----------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5496f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns\n",
    "df_spark = df_spark.drop('Experience After 2 yrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9461dabc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+\n",
      "|  Name|Age|Experience|\n",
      "+------+---+----------+\n",
      "|  Abhi| 26|        10|\n",
      "|  Neha| 27|         8|\n",
      "|Milind| 27|         4|\n",
      "+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5429e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Rename the columns\n",
    "df_spark = df_spark.withColumnRenamed('Name','Nav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "accb52d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----------+\n",
      "|   Nav|Age|Experience|\n",
      "+------+---+----------+\n",
      "|  Abhi| 26|        10|\n",
      "|  Neha| 27|         8|\n",
      "|Milind| 27|         4|\n",
      "+------+---+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b88187b",
   "metadata": {},
   "source": [
    "Pyspark Handling Missing Values   \n",
    "* Dropping columns   \n",
    "* Dropping Rows   \n",
    "* Various Parameter in Dropping functionalities   \n",
    "* Handling Missing values by Mean , median and mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28292589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| Age|Experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "|   Abhi|  26|        10| 30000|\n",
      "|   Neha|  27|         8| 40000|\n",
      "| Milind|  27|         4| 30000|\n",
      "|   Minu|  25|         6| 50000|\n",
      "|   Paul|  23|         8| 30000|\n",
      "| Harsha|  25|         5| 60000|\n",
      "|Shubham|  25|         4| 20000|\n",
      "| Mahesh|null|      null|100000|\n",
      "|   null|  34|        10| 38000|\n",
      "|   null|  36|      null|  null|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_spark = spark.read.csv('Book2.csv', header=True,inferSchema=True)\n",
    "df2_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7f17e1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+------+\n",
      "| Age|Experience|Salary|\n",
      "+----+----------+------+\n",
      "|  26|        10| 30000|\n",
      "|  27|         8| 40000|\n",
      "|  27|         4| 30000|\n",
      "|  25|         6| 50000|\n",
      "|  23|         8| 30000|\n",
      "|  25|         5| 60000|\n",
      "|  25|         4| 20000|\n",
      "|null|      null|100000|\n",
      "|  34|        10| 38000|\n",
      "|  36|      null|  null|\n",
      "+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Drop the cols\n",
    "df2_spark.drop('Name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "32878235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| Age|Experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "|   Abhi|  26|        10| 30000|\n",
      "|   Neha|  27|         8| 40000|\n",
      "| Milind|  27|         4| 30000|\n",
      "|   Minu|  25|         6| 50000|\n",
      "|   Paul|  23|         8| 30000|\n",
      "| Harsha|  25|         5| 60000|\n",
      "|Shubham|  25|         4| 20000|\n",
      "| Mahesh|null|      null|100000|\n",
      "|   null|  34|        10| 38000|\n",
      "|   null|  36|      null|  null|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ba215731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|Age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "|   Abhi| 26|        10| 30000|\n",
      "|   Neha| 27|         8| 40000|\n",
      "| Milind| 27|         4| 30000|\n",
      "|   Minu| 25|         6| 50000|\n",
      "|   Paul| 23|         8| 30000|\n",
      "| Harsha| 25|         5| 60000|\n",
      "|Shubham| 25|         4| 20000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_spark.na.drop().show() #by defalut how == any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67d6e343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| Age|Experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "|   Abhi|  26|        10| 30000|\n",
      "|   Neha|  27|         8| 40000|\n",
      "| Milind|  27|         4| 30000|\n",
      "|   Minu|  25|         6| 50000|\n",
      "|   Paul|  23|         8| 30000|\n",
      "| Harsha|  25|         5| 60000|\n",
      "|Shubham|  25|         4| 20000|\n",
      "| Mahesh|null|      null|100000|\n",
      "|   null|  34|        10| 38000|\n",
      "|   null|  36|      null|  null|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# any == how\n",
    "df2_spark.na.drop(how=\"all\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0f2bb800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| Age|Experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "|   Abhi|  26|        10| 30000|\n",
      "|   Neha|  27|         8| 40000|\n",
      "| Milind|  27|         4| 30000|\n",
      "|   Minu|  25|         6| 50000|\n",
      "|   Paul|  23|         8| 30000|\n",
      "| Harsha|  25|         5| 60000|\n",
      "|Shubham|  25|         4| 20000|\n",
      "| Mahesh|null|      null|100000|\n",
      "|   null|  34|        10| 38000|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_spark.na.drop(how=\"any\", thresh=2).show()  # atleast 2 not null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4fc29fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|Age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "|   Abhi| 26|        10| 30000|\n",
      "|   Neha| 27|         8| 40000|\n",
      "| Milind| 27|         4| 30000|\n",
      "|   Minu| 25|         6| 50000|\n",
      "|   Paul| 23|         8| 30000|\n",
      "| Harsha| 25|         5| 60000|\n",
      "|Shubham| 25|         4| 20000|\n",
      "|   null| 34|        10| 38000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_spark.na.drop(how=\"any\", thresh=3).show()  # atleast 2 not null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6d317465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|Age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "|   Abhi| 26|        10| 30000|\n",
      "|   Neha| 27|         8| 40000|\n",
      "| Milind| 27|         4| 30000|\n",
      "|   Minu| 25|         6| 50000|\n",
      "|   Paul| 23|         8| 30000|\n",
      "| Harsha| 25|         5| 60000|\n",
      "|Shubham| 25|         4| 20000|\n",
      "|   null| 34|        10| 38000|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Subset\n",
    "df2_spark.na.drop(how='any',subset=['Experience']).show() #Drop nan values form exp col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0601aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+----------+------+\n",
      "|          Name| Age|Experience|Salary|\n",
      "+--------------+----+----------+------+\n",
      "|          Abhi|  26|        10| 30000|\n",
      "|          Neha|  27|         8| 40000|\n",
      "|        Milind|  27|         4| 30000|\n",
      "|          Minu|  25|         6| 50000|\n",
      "|          Paul|  23|         8| 30000|\n",
      "|        Harsha|  25|         5| 60000|\n",
      "|       Shubham|  25|         4| 20000|\n",
      "|        Mahesh|null|      null|100000|\n",
      "|Missing Values|  34|        10| 38000|\n",
      "|Missing Values|  36|      null|  null|\n",
      "+--------------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_spark.na.fill('Missing Values').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "15931b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+\n",
      "|   Name| Age|Experience|Salary|\n",
      "+-------+----+----------+------+\n",
      "|   Abhi|  26|        10| 30000|\n",
      "|   Neha|  27|         8| 40000|\n",
      "| Milind|  27|         4| 30000|\n",
      "|   Minu|  25|         6| 50000|\n",
      "|   Paul|  23|         8| 30000|\n",
      "| Harsha|  25|         5| 60000|\n",
      "|Shubham|  25|         4| 20000|\n",
      "| Mahesh|null|      null|100000|\n",
      "|   null|  34|        10| 38000|\n",
      "|   null|  36|      null|  null|\n",
      "+-------+----+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "21647889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "56fcf5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer( inputCols=['Age','Experience','Salary'], \n",
    "                  outputCols=[\"{}_imputed\".format(c) for c in ['Age','Experience','Salary']]\n",
    "                 ).setStrategy('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e561017d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "|   Name| Age|Experience|Salary|Age_imputed|Experience_imputed|Salary_imputed|\n",
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "|   Abhi|  26|        10| 30000|         26|                10|         30000|\n",
      "|   Neha|  27|         8| 40000|         27|                 8|         40000|\n",
      "| Milind|  27|         4| 30000|         27|                 4|         30000|\n",
      "|   Minu|  25|         6| 50000|         25|                 6|         50000|\n",
      "|   Paul|  23|         8| 30000|         23|                 8|         30000|\n",
      "| Harsha|  25|         5| 60000|         25|                 5|         60000|\n",
      "|Shubham|  25|         4| 20000|         25|                 4|         20000|\n",
      "| Mahesh|null|      null|100000|         27|                 6|        100000|\n",
      "|   null|  34|        10| 38000|         34|                10|         38000|\n",
      "|   null|  36|      null|  null|         36|                 6|         44222|\n",
      "+-------+----+----------+------+-----------+------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df2_spark).transform(df2_spark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "961344ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer( inputCols=['Age','Experience','Salary'], \n",
    "                  outputCols=['Age','Experience','Salary']\n",
    "                 ).setStrategy('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "297b3944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+----------+------+\n",
      "|   Name|Age|Experience|Salary|\n",
      "+-------+---+----------+------+\n",
      "|   Abhi| 26|        10| 30000|\n",
      "|   Neha| 27|         8| 40000|\n",
      "| Milind| 27|         4| 30000|\n",
      "|   Minu| 25|         6| 50000|\n",
      "|   Paul| 23|         8| 30000|\n",
      "| Harsha| 25|         5| 60000|\n",
      "|Shubham| 25|         4| 20000|\n",
      "| Mahesh| 27|         6|100000|\n",
      "|   null| 34|        10| 38000|\n",
      "|   null| 36|         6| 44222|\n",
      "+-------+---+----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imputer.fit(df2_spark).transform(df2_spark).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b549bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
